{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e74f4144-0ae8-490d-819f-e2704eb5bc7c",
   "metadata": {},
   "source": [
    "## Example inference on the Iris flower dataset\n",
    "In this example, we demonstrate how to learn using a Negative Log Likelihood (NLL) loss with the uGMM-NN model on the Iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0e5408-f8f6-4804-950c-10c0663da0cd",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6066a21-3a22-4be0-aba5-f1037506f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(cwd, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from spn import SPN, Layer\n",
    "from variable_layer import *\n",
    "from gmm_layer import *\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb361afc-8868-4a2d-80d1-03b126f42ced",
   "metadata": {},
   "source": [
    "## Define code to perform bruteforce MPE inference on the class variable\n",
    "Due to the lack of an efficient MPE (Most Probable Explanation) inference algorithm in the uGMM-NN model, inference is performed by evaluating the model separately for each possible class label. In effect, this treats the class variable as a batch of hypotheses, performing one forward pass per class.\n",
    "\n",
    "For the Iris dataset, this approach is feasible because the number of class labels (3 classes) is small.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f714730-8948-494b-bdbe-77711d1dc49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNLLMPE(spn, data, label, device, epoch):\n",
    "    mpe = spn.infer_mpe(data, mpe_vars=[4], mpe_states=[0.,1.,2.])\n",
    "    predictions = mpe.argmax(dim=0).squeeze()\n",
    "    accuracy = (predictions == label).sum() / len(label)\n",
    "    print(f'epoch: {epoch}%, MPE Accuracy: {accuracy * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2af2bd-9307-4df1-b921-47e05c1286ea",
   "metadata": {},
   "source": [
    "## Define the model architecture:\n",
    "\n",
    "Layers in a uGMM-NN model are organized similarly to a standard multilayer perceptron (MLP) architecture, with sequential layers transforming the data from input to output. The model begins with a variable layer representing the input features. This is followed by multiple fully connected Gaussian Mixture layers, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38ff2741-ed55-4b22-870a-47d1bfc4f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iris_nll_fc_ugmm(device):\n",
    "    n_variables = 5\n",
    "    spn = SPN(device)\n",
    "\n",
    "    leaf_layer = VariableLayer(n_variables=n_variables, n_var_nodes=5) \n",
    "    spn.addLayer(leaf_layer)\n",
    "\n",
    "    layer1 = GMixture(prev_layer=spn.layers[-1], n_prod_nodes=20)\n",
    "    spn.addLayer(layer1)\n",
    "    \n",
    "    layer2 = GMixture(prev_layer=spn.layers[-1], n_prod_nodes=8)\n",
    "    spn.addLayer(layer2)\n",
    "\n",
    "    root_layer = GMixture(prev_layer=spn.layers[-1], n_prod_nodes=1)\n",
    "    root_layer.type = TYPE_GPRODUCT_ROOT\n",
    "    spn.addLayer(root_layer)\n",
    "    return spn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb5dca0-5581-4692-a378-f43d829e7d45",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c841e8df-ad8d-4c58-9d26-7c819bf21365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classify_iris_nll():\n",
    "      device = \"cpu\"\n",
    "      # device = \"cuda\"\n",
    "      random_seed = 0\n",
    "      torch.manual_seed(random_seed)\n",
    "      features, label = load_iris(return_X_y=True)\n",
    "      scaler = StandardScaler()\n",
    "      features = scaler.fit_transform(features)\n",
    "      features = torch.tensor(features, dtype=torch.float32).to(device)\n",
    "      label = torch.tensor(label, dtype=torch.int).to(device)\n",
    "      data = torch.cat([features, label.unsqueeze(1).int()], dim=1).to(device)\n",
    "\n",
    "      spn = iris_nll_fc_ugmm(device)\n",
    "      optimizer = torch.optim.Adam(spn.parameters(), lr=0.001)\n",
    "\n",
    "      for i in range(3000):\n",
    "            optimizer.zero_grad()\n",
    "            output = spn.infer(data, training=True)\n",
    "            loss = -1 * output.mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 200 == 0:\n",
    "                  print(f\"Epoch: {i}, log-likelihood: {output.sum().item():10.4f}\")\n",
    "                  predictNLLMPE(spn, data, label, device, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "812a9009-6846-4aad-ac35-5796d5dcfa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, log-likelihood:  -474.2241\n",
      "epoch: 0%, MPE Accuracy: 37.33333206176758%\n",
      "Epoch: 200, log-likelihood:  -221.9651\n",
      "epoch: 200%, MPE Accuracy: 62.0%\n",
      "Epoch: 400, log-likelihood:  -122.2520\n",
      "epoch: 400%, MPE Accuracy: 69.33333587646484%\n",
      "Epoch: 600, log-likelihood:   -68.5943\n",
      "epoch: 600%, MPE Accuracy: 80.0%\n",
      "Epoch: 800, log-likelihood:   -23.7078\n",
      "epoch: 800%, MPE Accuracy: 84.0%\n",
      "Epoch: 1000, log-likelihood:    23.6015\n",
      "epoch: 1000%, MPE Accuracy: 92.66666412353516%\n",
      "Epoch: 1200, log-likelihood:    76.9703\n",
      "epoch: 1200%, MPE Accuracy: 98.0%\n",
      "Epoch: 1400, log-likelihood:   137.1010\n",
      "epoch: 1400%, MPE Accuracy: 98.0%\n",
      "Epoch: 1600, log-likelihood:   201.3132\n",
      "epoch: 1600%, MPE Accuracy: 97.33333587646484%\n",
      "Epoch: 1800, log-likelihood:   262.8509\n",
      "epoch: 1800%, MPE Accuracy: 96.66666412353516%\n",
      "Epoch: 2000, log-likelihood:   318.1485\n",
      "epoch: 2000%, MPE Accuracy: 98.66667175292969%\n",
      "Epoch: 2200, log-likelihood:   367.4844\n",
      "epoch: 2200%, MPE Accuracy: 99.33333587646484%\n",
      "Epoch: 2400, log-likelihood:   412.1458\n",
      "epoch: 2400%, MPE Accuracy: 100.0%\n",
      "Epoch: 2600, log-likelihood:   453.4484\n",
      "epoch: 2600%, MPE Accuracy: 100.0%\n",
      "Epoch: 2800, log-likelihood:   492.1013\n",
      "epoch: 2800%, MPE Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "Classify_iris_nll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3f77d4-1d8e-4d37-9109-63578a44d46c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
