{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e74f4144-0ae8-490d-819f-e2704eb5bc7c",
   "metadata": {},
   "source": [
    "## Example (discriminative) inference on the MNIST dataset\n",
    "In this example, we demonstrate how to perform classification on the MNIST dataset using a fully connected deep univariate Gaussian Mixture Model (uGMM-NN) network trained with a **cross-entropy loss**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0e5408-f8f6-4804-950c-10c0663da0cd",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6066a21-3a22-4be0-aba5-f1037506f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(cwd, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from test_architectures import *\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb361afc-8868-4a2d-80d1-03b126f42ced",
   "metadata": {},
   "source": [
    "## Define code to test accuracy\n",
    "After training, we can evaluate the uGMM-NN on the test set by comparing the predicted class with the true label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f714730-8948-494b-bdbe-77711d1dc49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testAccuracy(model, test_loader, device):\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (test_batch_data, test_batch_labels) in enumerate(test_loader):\n",
    "                batch_size = test_batch_data.shape[0]\n",
    "                data = test_batch_data.reshape(batch_size, 28*28)\n",
    "                data = data.to(device)\n",
    "                output = model.infer(data, training = False)\n",
    "                predictions = output.argmax(dim=1)\n",
    "                labels = test_batch_labels.to(device)\n",
    "                total += labels.size(0)\n",
    "                correct += (predictions == labels).sum().item()\n",
    "    \n",
    "        accuracy = correct / total\n",
    "        print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2af2bd-9307-4df1-b921-47e05c1286ea",
   "metadata": {},
   "source": [
    "## Define the model architecture:\n",
    "\n",
    "Layers in a uGMM-NN model are defined similarly to the standard MLP architecture. In this example architecture, we introduce a dropout of **p=0.2** in the first hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38ff2741-ed55-4b22-870a-47d1bfc4f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_fc_ugmm(device):\n",
    "    n_variables = 28*28\n",
    "    model = uGMMNet(device)\n",
    "\n",
    "    input_layer = InputLayer(n_variables=n_variables, n_var_nodes=n_variables) \n",
    "    model.addLayer(input_layer)   \n",
    "\n",
    "    g1 = uGMMLayer(prev_layer=model.layers[-1], n_ugmm_nodes=128, dropout=0.2)\n",
    "    model.addLayer(g1)\n",
    "\n",
    "    g2 = uGMMLayer(prev_layer=model.layers[-1], n_ugmm_nodes=64, dropout=0.0)\n",
    "    model.addLayer(g2)\n",
    " \n",
    "    root = uGMMLayer(prev_layer=model.layers[-1], n_ugmm_nodes=10, dropout=0.0)\n",
    "    model.addLayer(root)\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb5dca0-5581-4692-a378-f43d829e7d45",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c841e8df-ad8d-4c58-9d26-7c819bf21365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnistCrossEntropy():    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])    \n",
    "    torch.manual_seed(0)\n",
    "    batch_size = 256\n",
    "\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    device = \"cuda\"\n",
    "\n",
    "    model = mnist_fc_ugmm(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer, \n",
    "        milestones=[20, 45],\n",
    "        gamma=0.1\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_index, (inputs, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()  \n",
    "            batch_size = inputs.shape[0]\n",
    "            data = inputs.reshape(batch_size, 28*28)\n",
    "            data = data.to(device)\n",
    "            output = model.infer(data, training=True)\n",
    "            loss = criterion(output, labels.to(device))         \n",
    "            \n",
    "            loss.backward()  \n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n",
    "        testAccuracy(model, test_loader, device)\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "812a9009-6846-4aad-ac35-5796d5dcfa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.5083840489387512\n",
      "Test Accuracy: 90.10%\n",
      "Epoch 2/50, Loss: 0.43400970101356506\n",
      "Test Accuracy: 91.90%\n",
      "Epoch 3/50, Loss: 0.4375993013381958\n",
      "Test Accuracy: 92.64%\n",
      "Epoch 4/50, Loss: 0.24422836303710938\n",
      "Test Accuracy: 92.73%\n",
      "Epoch 5/50, Loss: 0.34684380888938904\n",
      "Test Accuracy: 94.46%\n",
      "Epoch 6/50, Loss: 0.19134074449539185\n",
      "Test Accuracy: 95.07%\n",
      "Epoch 7/50, Loss: 0.1892576664686203\n",
      "Test Accuracy: 95.29%\n",
      "Epoch 8/50, Loss: 0.32417571544647217\n",
      "Test Accuracy: 95.28%\n",
      "Epoch 9/50, Loss: 0.20768284797668457\n",
      "Test Accuracy: 95.49%\n",
      "Epoch 10/50, Loss: 0.18329529464244843\n",
      "Test Accuracy: 95.46%\n",
      "Epoch 11/50, Loss: 0.17306679487228394\n",
      "Test Accuracy: 95.73%\n",
      "Epoch 12/50, Loss: 0.08532044291496277\n",
      "Test Accuracy: 95.73%\n",
      "Epoch 13/50, Loss: 0.06585118919610977\n",
      "Test Accuracy: 95.98%\n",
      "Epoch 14/50, Loss: 0.12104979902505875\n",
      "Test Accuracy: 96.35%\n",
      "Epoch 15/50, Loss: 0.1453668177127838\n",
      "Test Accuracy: 96.11%\n",
      "Epoch 16/50, Loss: 0.13293862342834473\n",
      "Test Accuracy: 95.99%\n",
      "Epoch 17/50, Loss: 0.10576143115758896\n",
      "Test Accuracy: 96.41%\n",
      "Epoch 18/50, Loss: 0.10643907636404037\n",
      "Test Accuracy: 96.51%\n",
      "Epoch 19/50, Loss: 0.11100318282842636\n",
      "Test Accuracy: 96.34%\n",
      "Epoch 20/50, Loss: 0.11072471737861633\n",
      "Test Accuracy: 96.06%\n",
      "Epoch 21/50, Loss: 0.12309414148330688\n",
      "Test Accuracy: 97.22%\n",
      "Epoch 22/50, Loss: 0.06539837270975113\n",
      "Test Accuracy: 97.26%\n",
      "Epoch 23/50, Loss: 0.09001290798187256\n",
      "Test Accuracy: 97.31%\n",
      "Epoch 24/50, Loss: 0.12096968293190002\n",
      "Test Accuracy: 97.21%\n",
      "Epoch 25/50, Loss: 0.015700506046414375\n",
      "Test Accuracy: 97.20%\n",
      "Epoch 26/50, Loss: 0.06514734774827957\n",
      "Test Accuracy: 97.36%\n",
      "Epoch 27/50, Loss: 0.05437132716178894\n",
      "Test Accuracy: 97.27%\n",
      "Epoch 28/50, Loss: 0.06454989314079285\n",
      "Test Accuracy: 97.29%\n",
      "Epoch 29/50, Loss: 0.08573213964700699\n",
      "Test Accuracy: 97.38%\n",
      "Epoch 30/50, Loss: 0.0702514722943306\n",
      "Test Accuracy: 97.36%\n",
      "Epoch 31/50, Loss: 0.054589733481407166\n",
      "Test Accuracy: 97.21%\n",
      "Epoch 32/50, Loss: 0.08767048269510269\n",
      "Test Accuracy: 97.41%\n",
      "Epoch 33/50, Loss: 0.05853436887264252\n",
      "Test Accuracy: 97.54%\n",
      "Epoch 34/50, Loss: 0.10279133170843124\n",
      "Test Accuracy: 97.40%\n",
      "Epoch 35/50, Loss: 0.12227626889944077\n",
      "Test Accuracy: 97.40%\n",
      "Epoch 36/50, Loss: 0.041345637291669846\n",
      "Test Accuracy: 97.40%\n",
      "Epoch 37/50, Loss: 0.041789036244153976\n",
      "Test Accuracy: 97.42%\n",
      "Epoch 38/50, Loss: 0.015588917769491673\n",
      "Test Accuracy: 97.35%\n",
      "Epoch 39/50, Loss: 0.08995000272989273\n",
      "Test Accuracy: 97.39%\n",
      "Epoch 40/50, Loss: 0.017167652025818825\n",
      "Test Accuracy: 97.31%\n",
      "Epoch 41/50, Loss: 0.14352060854434967\n",
      "Test Accuracy: 97.51%\n",
      "Epoch 42/50, Loss: 0.05925427004694939\n",
      "Test Accuracy: 97.34%\n",
      "Epoch 43/50, Loss: 0.034476593136787415\n",
      "Test Accuracy: 97.23%\n",
      "Epoch 44/50, Loss: 0.09311706572771072\n",
      "Test Accuracy: 97.51%\n",
      "Epoch 45/50, Loss: 0.012964221648871899\n",
      "Test Accuracy: 97.44%\n",
      "Epoch 46/50, Loss: 0.029748693108558655\n",
      "Test Accuracy: 97.51%\n",
      "Epoch 47/50, Loss: 0.03861802816390991\n",
      "Test Accuracy: 97.51%\n",
      "Epoch 48/50, Loss: 0.027262484654784203\n",
      "Test Accuracy: 97.56%\n",
      "Epoch 49/50, Loss: 0.01616567187011242\n",
      "Test Accuracy: 97.52%\n",
      "Epoch 50/50, Loss: 0.016350887715816498\n",
      "Test Accuracy: 97.46%\n"
     ]
    }
   ],
   "source": [
    "mnistCrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3f77d4-1d8e-4d37-9109-63578a44d46c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
